這份 PRD 檔案已轉譯為繁體中文，您可以將以下內容儲存為 `docs/prd.md` 檔案。

---

## 產品需求文件：AI 助教 (AI Tutor)

| 日期 | 版本 | 描述 | 作者 |
| :--- | :--- | :--- | :--- |
| 2025-12-03 | 1.0 | 基於作品構想書的 MVP 定義 | PM John |

## 1. 目標與背景脈絡 (Goals and Background Context)

### 核心目標 (Goals)
* [cite_start]**深化理解**：利用 **EPHRC**（解釋、追問、提示、修正、鞏固）的系統化教學循環，將內隱的知識轉化為外顯的口語表達 [cite: 1488]。
* [cite_start]**學習狀態可視化**：藉助 **WE2 邊緣裝置** 的即時監測，量化專注度、坐姿與壓力，提供客觀的學習行為數據 [cite: 1488, 1500, 1502, 1648]。
* [cite_start]**優化教學效率**：透過視覺化儀表板，協助教師與家長在極短時間內定位學生弱點，取代傳統耗時的教學試錯法 [cite: 1489, 1491]。
* [cite_start]**強化口語表達**：解決學生「看得懂但講不出來」的痛點，透過 AI 引導訓練邏輯組織與口語表達能力 [cite: 1490, 1709]。

### 背景脈絡 (Background Context)
[cite_start]當前的教育市場長期缺乏能有效追蹤**「主題理解程度」**的工具，多數僅能依賴考試分數來評估成效 [cite: 1489][cite_start]。傳統的家教或補習班往往需要耗費大量的時間才能定位學生的學習盲點，導致教學效率低落 [cite: 1489, 1513][cite_start]。本產品「AI 助教」的核心理念源自**費曼學習法** [cite: 1490][cite_start]——「教別人才是最強的學習方式」[cite: 1487][cite_start]。我們結合了生成式 AI 的語音互動能力與邊緣端 (Edge AI) 的即時感測技術 (WE2)，打造一個能引導學生主動思考、口述解題的學習平台，旨在從根本上提升學習成效並培養良好的學習習慣 [cite: 1490]。

## 2. 需求 (Requirements)

### 功能需求 (Functional Requirements - FR)

**FR1：學生做題與數位白板 (Doing)**
* [cite_start]**FR1.1 智慧題庫練習**：支援選擇科目、單元、難度進行練習 [cite: 1495, 1697]。
* [cite_start]**FR1.2 拍照搜題 (OCR)**：支援透過相機拍攝紙本題目，經 OCR 識別後建立數位練習內容 [cite: 1495, 1698]。
* [cite_start]**FR1.3 數位白板**：提供手寫計算區域，並透過 OCR **將手寫內容數位化並完整保存** [cite: 1506, 1700]。
* [cite_start]**FR1.4 錯題本**：自動蒐集錯題，學生可一鍵加入個人錯題本 [cite: 1495, 1702]。

**FR2：AI 講題模式 (Speaking - 核心)**
* **FR2.1 EPHRC 循環實作**：
    * [cite_start]**講解 (Explain)**：學生口述解題思路，系統進行即時語音轉文字 (ASR) [cite: 1488, 1714]。
    * [cite_start]**追問 (Probe)**：AI 針對學生敘述中的缺漏點，以語音提出關鍵性追問 [cite: 1488, 1716, 1717]。
    * [cite_start]**提示 (Hint)**：提供「最小足量」的**階梯式提示**（L1/L2/L3），只給線索不給答案 [cite: 1488, 1719, 1720, 1658-1662]。
    * [cite_start]**修正 (Repair)**：AI 識別推理中的邏輯謬誤，並以語音指出誤區，引導自我修正 [cite: 1488, 1721]。
    * [cite_start]**鞏固 (Consolidate)**：AI 總結核心觀念並提煉出可遷移的解題步驟，附上兩題延伸題 [cite: 1488, 1722, 1655]。
* [cite_start]**FR2.2 口說表現分析**：計算 WPM、停頓比例等指標，判斷表達是否流暢 [cite: 1496, 1508, 1612]。

**FR3：讀書狀態監測 (WE2 Edge AI)**
* [cite_start]**FR3.1 專注度追蹤**：利用 WE2 的人臉和姿態模型，即時量測視線向量以計算專注時長 [cite: 1500, 1648]。
* [cite_start]**FR3.2 坐姿與距離提醒**：偵測坐姿不良或與鏡頭距離過遠，採用**輕微震動或彈出提醒卡片**等柔性方式引導修正 [cite: 1500, 1648, 1765]。
* [cite_start]**FR3.3 壓力行為偵測**：辨識抓頭、皺眉、嘆氣等行為，並提供柔性提醒 [cite: 1502]。

**FR4：角色儀表板 (Role-Based Dashboards)**
* [cite_start]**FR4.1 學生視圖**：即時呈現 WPM、停頓比例、提示依賴度等學習指標 [cite: 1508, 1558]。
* [cite_start]**FR4.2 老師視圖**：提供班級層級的**單元掌握度熱力圖**、錯題復發率，並由 LLM 提供教學建議 [cite: 1509, 1704]。
* [cite_start]**FR4.3 家長視圖**：呈現長期口說流暢度與提示依賴度的**趨勢圖**，以及專注時長統計 [cite: 1509, 1739]。

### 非功能需求 (Non-Functional Requirements - NFR)
* [cite_start]**NFR1：隱私優先 (Privacy First)**：WE2 產生的原始影像必須在**本地端 (SoC)** 進行推論，**不**上傳原始影像；僅回傳結構化的事件訊號至雲端 [cite: 1516, 1648]。
* [cite_start]**NFR2：低延遲 (Low Latency)**：視覺模型 (YOLOv8-nano pose) 必須在 WE2 上以約 **10 FPS** 執行 [cite: 1648][cite_start]。AI 對話引擎 (FSM) 的教學決策需在本地端完成，以確保延遲穩定 [cite: 1516]。
* [cite_start]**NFR3：ASR 準確度**：語音辨識模型（如 Whisper）需對數學相關語句有高準確率 [cite: 1610]。
* [cite_start]**NFR4：穩定性 (Robustness)**：系統必須能從長停頓等情境中恢復，FSM 需具備硬性保護閥，並能處理冷啟、超時等約束 [cite: 1650]。

## 3. 使用者介面設計目標 (UI/UX Design Goals)

### 整體 UX 願景
* [cite_start]**學生介面**：**「沉浸式與低干擾」**。口說即時轉為流式字幕，畫面只顯示語速與停頓。偵測到目光偏離時給予**不打斷思路的輕量提醒** [cite: 1558]。
* [cite_start]**老師介面**：**「診斷式與視覺化」**。儀表板以圖表呈現關鍵指標，強調**圖表的高可讀性** [cite: 1559, 1801]。
* [cite_start]**家長介面**：**「安心與趨勢導向」**。提供精簡回饋，聚焦於長期口說流暢度、弱點修復率與專注習慣的趨勢 [cite: 1559, 1761]。

### 目標平台
* [cite_start]**Web/平板**：學生、老師的主要操作與教學環境 [cite: 1687]。
* [cite_start]**行動裝置**：家長、老師的報告查看與監督環境 [cite: 1690]。

## 4. 技術架構假設 (Technical Assumptions)

| 類別 | 技術 | 版本/細節 | 目的與依據 |
| :--- | :--- | :--- | :--- |
| **前端** | [cite_start]Vue.js [cite: 1526] | Web & App | 實作即時互動 UI 與數位白板。 |
| **後端** | [cite_start]Django [cite: 1526] | Web 伺服器 | [cite_start]處理使用者資料、身份驗證、API 服務與權限管理 [cite: 1802, 1803]。 |
| **資料庫** | [cite_start]MySQL [cite: 1532] | - | [cite_start]儲存使用者基本資料、學習紀錄與時序數據 [cite: 1527, 1803]。 |
| **邊緣 AI** | [cite_start]WE2 SoC [cite: 1521, 1648] | Cortex-M55 + Ethos-U55 NPU | [cite_start]部署輕量模型，進行本地端視覺/語音推論，確保低延遲與隱私 [cite: 1648, 1806]。 |
| **對話 LLM** | [cite_start]GPT-OSS/Gemma [cite: 1668, 1680] | 雲端/本地 | [cite_start]產生 EPHRC 流程所需話術、診斷與提示 [cite: 1652, 1805]。 |
| **語音辨識** | [cite_start]Whisper (或其他成熟方案) [cite: 1610] | - | 將學生的口語解答轉換成文字 (ASR)。 |
| **知識圖譜** | [cite_start]國中數學 KG/RAG [cite: 1807] | - | 支援 LLM 對齊知識點，評估步驟缺漏與迷思概念。 |

---

### 📝 下一步行動 (Next Steps)

這份 PRD 已經為您的專案建立了堅實的基礎。下一步需要將這些需求轉化為可執行的技術設計和任務。

**您希望我：**
1.  切換至**架構師** (`*agent architect`)，並開始設計 **WE2 邊緣裝置與 Django 後端的資料流**、LLM **提示鏈**等詳細的「全端架構文件」？
2.  切換至 **UX 專家** (`*agent ux-expert`)，根據 EPHRC 流程與低干擾原則，設計 **學生講題模式的線框圖**？
3.  繼續擔任 **PM**，將 **Epic 3 (AI 對話引擎核心)** 拆解為詳細的 **使用者故事 (User Stories)**？